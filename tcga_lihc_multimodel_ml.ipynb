# OS-level operations (file paths, working directory)
import os
# Data handling and numerical computation
import pandas as pd          # Tabular data (DataFrames)
import numpy as np           # Numerical operations
# Data splitting and validation
from sklearn.model_selection import train_test_split
# Feature scaling
from sklearn.preprocessing import StandardScaler
# Machine learning models
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
# Model evaluation metrics
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import roc_curve, auc
# Visualization
import matplotlib.pyplot as plt
# Explainable AI
import shap
# Create output directories if they do not exist
os.makedirs("Data", exist_ok=True)
os.makedirs("Results", exist_ok=True)
os.makedirs("Figures", exist_ok=True)
# Get current working directory
print("Working directory:", os.getcwd())
# Load TCGA-LIHC RNA-seq STAR counts data
expr = pd.read_csv(
    "../Data/TCGA-LIHC.star_counts.tsv",
    sep="\t",
    index_col=0
)
# Check the dimensions of the dataset (genes × samples)
print(expr.shape)
# Preview the first 5 rows of the gene expression matrix
expr.head()
# Transpose the expression matrix so that samples are rows and genes are columns
expr_t = expr.T
# Check the new shape after transposing (samples × genes)
print(expr_t.shape)
# Preview the first 5 samples with gene expression values
expr_t.head()
# View the first 5 sample IDs (TCGA barcodes)
expr_t.index[:5]
# Extract sample type code from TCGA sample ID
# "01" = Primary Tumor, "11" = Solid Tissue Normal
expr_t["sample_type"] = expr_t.index.str[13:15]
# Create binary label for supervised learning
# 1 = Tumor, 0 = Normal
expr_t["label"] = expr_t["sample_type"].apply(
    lambda x: 1 if x == "01" else 0
)
# Check the number of tumor and normal samples
expr_t["label"].value_counts()
# Define feature matrix (gene expression values only)
X = expr_t.drop(columns=["sample_type", "label"])
# Define target vector (tumor vs normal labels)
y = expr_t["label"]
# Verify dimensions of features and labels
print(X.shape)
print(y.shape)
# Calculate variance for each gene across all samples
gene_variance = X.var()
# Remove genes with zero variance (no expression change across samples)
X = X.loc[:, gene_variance > 0]
# Check the shape after filtering non-informative genes
print(X.shape)
# Save processed feature matrix and labels
X.to_csv("../Results/processed_expression_matrix.csv")
y.to_csv("../Results/labels_tumor_normal.csv")
# Split the dataset into training (80%) and testing (20%) sets 
X_train, X_test, y_train, y_test = train_test_split(
    X,
    y,
    test_size=0.2,
    random_state=42,
    stratify=y
)
# Check the dimensions of the training and testing feature matrix
print(X_train.shape)
print(X_test.shape)
# Initialize the standard scaler to normalize features
scaler = StandardScaler()
# Fit the scaler on training data and scale the training features
X_train_scaled = scaler.fit_transform(X_train)
# Apply the same scaling parameters to the test data
X_test_scaled = scaler.transform(X_test)
# Initialize Logistic Regression classifier for binary classification
model = LogisticRegression(
    max_iter=5000,
    solver="liblinear"
)
# Train the Logistic Regression model using scaled training data
model.fit(X_train_scaled, y_train)
# Predict tumor/normal labels for the test dataset
y_pred = model.predict(X_test_scaled)
# Calculate and display overall classification accuracy
print("Accuracy:", accuracy_score(y_test, y_pred))
# Display detailed classification metrics (precision, recall, F1-score)
print(classification_report(y_test, y_pred))
# Predict probability scores for the tumor class (label = 1)
# Save Logistic Regression evaluation metrics
logreg_report = classification_report(y_test, y_pred, output_dict=True)
pd.DataFrame(logreg_report).to_csv(
    "../Results/logreg_classification_report.csv"
)
y_prob = model.predict_proba(X_test_scaled)[:, 1]
# Compute False Positive Rate (FPR) and True Positive Rate (TPR)
fpr, tpr, _ = roc_curve(y_test, y_prob)
# Calculate Area Under the ROC Curve (AUC)
roc_auc = auc(fpr, tpr)
# Create a new figure for the ROC curve
plt.figure()
# Plot the ROC curve using false positive rate and true positive rate
plt.plot(fpr, tpr, label=f"ROC curve (AUC = {roc_auc:.2f})")
# Plot the diagonal line representing random classifier performance
plt.plot([0, 1], [0, 1], linestyle="--")
# Label the x-axis as False Positive Rate
plt.xlabel("False Positive Rate")
# Label the y-axis as True Positive Rate
plt.ylabel("True Positive Rate")
# Add a title to the ROC plot
plt.title("ROC Curve – Tumor vs Normal")
# Display the legend showing the AUC value
plt.legend()
#Save the plot
plt.savefig("../Figures/roc_logistic_regression.png", dpi=300)
# Render the ROC curve plot
plt.show()
# Extract the learned coefficients from the Logistic Regression model
coef = model.coef_[0]
# Create a DataFrame mapping each gene to its corresponding coefficient
coef_df = pd.DataFrame({
    "Gene": X.columns,
    "Coefficient": coef
})
# Compute the absolute value of coefficients to measure strength of gene influence
coef_df["abs_coef"] = coef_df["Coefficient"].abs()
# Sort genes by absolute coefficient value (most influential genes first)
coef_df = coef_df.sort_values("abs_coef", ascending=False)
# Display the top 20 most influential genes
coef_df.head(20)
# Select top 20 genes positively associated with tumor samples
tumor_genes = coef_df[coef_df["Coefficient"] > 0].head(20)
# Select top 20 genes negatively associated with tumor samples (normal-associated genes)
normal_genes = coef_df[coef_df["Coefficient"] < 0].head(20)
# Display tumor-associated and normal-associated gene lists
tumor_genes, normal_genes
# Save Logistic Regression gene coefficients and biological gene lists
coef_df.to_csv(
    "../Results/logistic_regression_gene_coefficients.csv",
    index=False
)
tumor_genes.to_csv(
    "../Results/tumor_associated_genes_logreg.csv",
    index=False
)
normal_genes.to_csv(
    "../Results/normal_associated_genes_logreg.csv",
    index=False
)
# Initialize Random Forest classifier for non-linear tumor vs normal classification
rf_model = RandomForestClassifier(
    n_estimators=300,
    random_state=42,
    n_jobs=-1
)
# Train the Random Forest model on the training dataset
rf_model.fit(X_train, y_train)
# Predict tumor/normal labels for the test dataset
y_pred_rf = rf_model.predict(X_test)
# Calculate and display accuracy for the Random Forest model
print("RF Accuracy:", accuracy_score(y_test, y_pred_rf))
# Display detailed classification metrics for the Random Forest model
print(classification_report(y_test, y_pred_rf))
# Save Random Forest evaluation metrics
rf_report = classification_report(y_test, y_pred_rf, output_dict=True)
pd.DataFrame(rf_report).to_csv(
    "../Results/rf_classification_report.csv"
)
# Predict probability scores for the positive class (Tumor = 1)
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]
# Compute False Positive Rate (FPR) and True Positive Rate (TPR)
fpr, tpr, _ = roc_curve(y_test, y_prob_rf)
# Calculate the Area Under the ROC Curve (AUC)
roc_auc = auc(fpr, tpr)
# Create a new figure for plotting the ROC curve
plt.figure()
# Plot the ROC curve with AUC value displayed in the legend
plt.plot(fpr, tpr, label=f"Random Forest ROC curve (AUC = {roc_auc:.2f})")
# Plot the diagonal reference line representing random classifier performance
plt.plot([0, 1], [0, 1], linestyle="--")
# Label the x-axis as False Positive Rate
plt.xlabel("False Positive Rate")
# Label the y-axis as True Positive Rate
plt.ylabel("True Positive Rate")
# Add a descriptive title for the ROC curve
plt.title("Random Forest ROC Curve – Tumor vs Normal")
# Display the legend showing the ROC curve and AUC value
plt.legend()
# Save the ROC curve figure to disk at high resolution
plt.savefig("../Figures/roc_random_forest.png", dpi=300)
# Render the ROC curve plot
plt.show()
# Extract feature importance scores from the trained Random Forest model
rf_importance = pd.DataFrame({
    "Gene": X.columns,
    "Importance": rf_model.feature_importances_
})
# Sort genes by Random Forest importance score (highest first)
rf_importance = rf_importance.sort_values(
    "Importance",
    ascending=False
)
# Display the top 20 most important genes according to the Random Forest model
rf_importance.head(20)
# Save Random Forest gene importance
rf_importance.to_csv(
    "../Results/random_forest_gene_importance.csv",
    index=False
)
# Initialize XGBoost classifier for binary tumor vs normal classification
xgb_model = XGBClassifier(
    n_estimators=200,
    max_depth=5,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    objective="binary:logistic",
    eval_metric="logloss",
    tree_method="hist",  
    n_jobs=-1,
    random_state=42
)
# Train the XGBoost model using training data
# Convert pandas DataFrames to NumPy arrays for XGBoost compatibility
xgb_model.fit(
    X_train.values,  
    y_train.values
)
# Predict tumor/normal labels on the test dataset using the XGBoost model
y_pred_xgb = xgb_model.predict(X_test.values)
# Calculate and display accuracy for the XGBoost model
print("XGBoost Accuracy:", accuracy_score(y_test, y_pred_xgb))
# Display detailed classification metrics for the XGBoost model
print(classification_report(y_test, y_pred_xgb))
# Save XGBoost evaluation metrics
xgb_report = classification_report(y_test, y_pred_xgb, output_dict=True)
pd.DataFrame(xgb_report).to_csv(
    "../Results/xgb_classification_report.csv"
)
# Predict probability scores for the tumor class (label = 1) using the XGBoost model
y_prob_xgb = xgb_model.predict_proba(X_test.values)[:, 1]
# Compute False Positive Rate (FPR) and True Positive Rate (TPR) for the XGBoost model
fpr, tpr, _ = roc_curve(y_test, y_prob_xgb)
# Calculate Area Under the ROC Curve (AUC) for the XGBoost model
roc_auc = auc(fpr, tpr)
# Create a new figure for the XGBoost ROC curve
plt.figure()
# Plot the ROC curve for the XGBoost model
plt.plot(fpr, tpr, label=f"XGBoost ROC (AUC = {roc_auc:.2f})")
# Plot the diagonal line representing random classifier performance
plt.plot([0, 1], [0, 1], linestyle="--")
# Label the x-axis as False Positive Rate
plt.xlabel("False Positive Rate")
# Label the y-axis as True Positive Rate
plt.ylabel("True Positive Rate")
# Add a title to the ROC plot
plt.title("XGBoost ROC – Tumor vs Normal")
# Display the legend showing the AUC value
plt.legend()
# Save the plot
plt.savefig("../Figures/roc_xgboost.png", dpi=300)
# Render the ROC curve plot
plt.show()
# Extract feature importance scores from the trained XGBoost model and map them to corresponding gene names
xgb_importance = pd.DataFrame({
    "Gene": X.columns,
    "Importance": xgb_model.feature_importances_
}).sort_values("Importance", ascending=False)
# Display the top 20 most important genes according to XGBoost
xgb_importance.head(20)
# Save XGBoost gene importance
xgb_importance.to_csv(
    "../Results/xgboost_gene_importance.csv",
    index=False
)
# Initialize SHAP TreeExplainer for the trained XGBoost model
explainer = shap.TreeExplainer(xgb_model)
# Randomly sample a subset of test data for SHAP analysis (for efficiency)
X_test_sample = X_test.sample(
    min(50, X_test.shape[0]),
    random_state=42
)
# Compute SHAP values for the sampled test data
# SHAP values quantify each gene's contribution to the model prediction
shap_values = explainer.shap_values(X_test_sample.values)
# Generate a SHAP summary plot
shap.summary_plot(
    shap_values,
    X_test_sample,
    feature_names=X.columns,
    max_display=20,
    show=False
)
# Save the plot
plt.savefig(
    "../Figures/shap_summary_xgboost.png",
    dpi=300,
    bbox_inches="tight"
)
# Display the plot
plt.show()
# Number of top-ranked genes to consider from each model
TOP_N = 50
# Select top N genes based on absolute coefficients from Logistic Regression
top_logreg_genes = set(coef_df.head(TOP_N)["Gene"])
# Select top N genes based on feature importance from Random Forest
top_rf_genes     = set(rf_importance.head(TOP_N)["Gene"])
# Select top N genes based on feature importance from XGBoost
top_xgb_genes    = set(xgb_importance.head(TOP_N)["Gene"])
# Identify genes common to all three models (model-independent features)
common_genes_all = (
    top_logreg_genes
    & top_rf_genes
    & top_xgb_genes
)
# Display the number of consensus genes
print("Number of common genes:", len(common_genes_all))
# View the list of consensus genes
common_genes_all
# Save the consensus gene list for downstream analysis and reproducibility
pd.DataFrame(
    {"Gene": list(common_genes_all)}
).to_csv(
    "../Results/common_genes_logreg_rf_xgb.csv",
    index=False
)
